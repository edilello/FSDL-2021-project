{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Text_Classification_For_Otomoto_Price_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeTNYv3KPavS"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeO766NWPb-7",
        "outputId": "77de57dd-adcb-4664-b370-d5eedb3076c3"
      },
      "source": [
        "!pip install transformers datasets"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.6.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cItz8NDVEQRr"
      },
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel,\\\n",
        "                            BertModel, BertTokenizer, AutoModelForQuestionAnswering, pipeline,\\\n",
        "                            Trainer, TrainingArguments, BertForSequenceClassification, RobertaTokenizer,\\\n",
        "                            TFRobertaForQuestionAnswering\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from datasets import list_metrics, load_metric\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x47tVvlETD_"
      },
      "source": [
        "## Load and pre-process data to try simply 2-class classification problem first: either the description leads to a positive or negative price estimation error\\\n",
        "df = pd.read_csv('drive/MyDrive/data/EU_motors_data/pl/PL_data_10k.csv')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VZA4kaskieqP",
        "outputId": "722404ee-331d-419c-fa38-cd4ff3488198"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price_eval_sk</th>\n",
              "      <th>ad_id</th>\n",
              "      <th>train</th>\n",
              "      <th>truncated_description</th>\n",
              "      <th>truncated_desc_length</th>\n",
              "      <th>prediction</th>\n",
              "      <th>error</th>\n",
              "      <th>pe</th>\n",
              "      <th>ape</th>\n",
              "      <th>discretized_pe</th>\n",
              "      <th>simple_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6078637720|PL|otomoto</td>\n",
              "      <td>6078637720</td>\n",
              "      <td>False</td>\n",
              "      <td>Do sprzedania Opla Vectra C GTS OPC Line z rok...</td>\n",
              "      <td>89</td>\n",
              "      <td>15084.661133</td>\n",
              "      <td>-2415.338867</td>\n",
              "      <td>-13.801936</td>\n",
              "      <td>13.801936</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6084599422|PL|otomoto</td>\n",
              "      <td>6084599422</td>\n",
              "      <td>False</td>\n",
              "      <td>Więcej zdjęć na OTOMOTO \\r\\n-świeżo sprowadzon...</td>\n",
              "      <td>44</td>\n",
              "      <td>22104.378906</td>\n",
              "      <td>4110.378906</td>\n",
              "      <td>22.843053</td>\n",
              "      <td>22.843053</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6084185721|PL|otomoto</td>\n",
              "      <td>6084185721</td>\n",
              "      <td>False</td>\n",
              "      <td>SKODA FABIA KOMBI\\r\\nROK PRODUKCJI 2008 model ...</td>\n",
              "      <td>171</td>\n",
              "      <td>13786.808594</td>\n",
              "      <td>-913.191406</td>\n",
              "      <td>-6.212186</td>\n",
              "      <td>6.212186</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6081681904|PL|otomoto</td>\n",
              "      <td>6081681904</td>\n",
              "      <td>False</td>\n",
              "      <td>Citroen C3 Picasso 1.6 Vti 120KM \\r\\n\\r\\nSamoc...</td>\n",
              "      <td>59</td>\n",
              "      <td>32854.804688</td>\n",
              "      <td>-145.195312</td>\n",
              "      <td>-0.439986</td>\n",
              "      <td>0.439986</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6082099343|PL|otomoto</td>\n",
              "      <td>6082099343</td>\n",
              "      <td>False</td>\n",
              "      <td>Witam,\\r\\nna sprzedaż Ford Transit Connect 5 o...</td>\n",
              "      <td>88</td>\n",
              "      <td>47534.355469</td>\n",
              "      <td>-7815.644531</td>\n",
              "      <td>-14.120406</td>\n",
              "      <td>14.120406</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           price_eval_sk       ad_id  ...  discretized_pe simple_class\n",
              "0  6078637720|PL|otomoto  6078637720  ...            -5.0            0\n",
              "1  6084599422|PL|otomoto  6084599422  ...             5.0            1\n",
              "2  6084185721|PL|otomoto  6084185721  ...            -3.0            0\n",
              "3  6081681904|PL|otomoto  6081681904  ...            -0.0            0\n",
              "4  6082099343|PL|otomoto  6082099343  ...            -5.0            0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvr_maFEulGi",
        "outputId": "074a2e42-030b-4448-d0e9-d69f1fbbc9db"
      },
      "source": [
        "df['simple_class'].value_counts() / len(df)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.6269\n",
              "0    0.3731\n",
              "Name: simple_class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE8wV7NjEaRB",
        "outputId": "d5a9c8b2-7deb-4192-c786-c69f7ad7fe6f"
      },
      "source": [
        "model_name = 'allegro/herbert-base-cased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at allegro/herbert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.sso.sso_relationship.weight', 'cls.sso.sso_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allegro/herbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gH9h1sShyCI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO6rRreRHnZO",
        "outputId": "6cb40308-dee7-4147-ada1-b64cdab490d5"
      },
      "source": [
        "# Get maximum possible length\n",
        "print(f\"Maximum number of tokens: {model.config.max_position_embeddings}\\n\")\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum number of tokens: 514\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAEfr9JzwoGO"
      },
      "source": [
        "# THERE MIGHT BE MORE PRE-PROCESSING NEEDED, AS THE MAX TOKENIZED LENGHT IS > 1500, WHILE I SELECTED ONLY THE FIRST 512 WORDS IN THE PRE-PROCESSING STEP\n",
        "# # Get the number of tokens in the text\n",
        "# df['tokenized_length'] = df['truncated_description'].apply(lambda row: len(tokenizer(row)['input_ids']))\n",
        "\n",
        "# print(df['tokenized_length'].describe())\n",
        "# df.tokenized_length.hist()\n",
        "# df.tokenized_length.hist()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC2LIczk82Gf"
      },
      "source": [
        "## Subsample data, take 30 minutes to tokenize 1M ads\n",
        "#num_ads_in_sample = 50000\n",
        "num_ads = len(df)\n",
        "df_sample = df.sample(num_ads_in_sample)\n",
        "df_sample.dropna(subset=['truncated_description', 'simple_class'], inplace=True)\n",
        "\n",
        "## Split into train and validation\n",
        "train, valid, test = np.split(df_sample.sample(frac=1, random_state=42),\n",
        "        [int(.7 * len(df_sample)), int(.9 * len(df_sample))])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bng2-1r36K18"
      },
      "source": [
        "## Let's save our descriptions and labels into lists\n",
        "train_descs, train_labels = train['truncated_description'].tolist(), train['simple_class'].tolist()\n",
        "valid_descs, valid_labels = valid['truncated_description'].tolist(), valid['simple_class'].tolist()\n",
        "test_descs, test_labels = test['truncated_description'].tolist(), test['simple_class'].tolist()\n",
        "\n",
        "## And encode with tokenizer\n",
        "MAX_LENGTH = 64\n",
        "train_encodings = tokenizer(train_descs, truncation=True, padding='max_length', max_length=MAX_LENGTH)\n",
        "val_encodings = tokenizer(valid_descs, truncation=True, padding='max_length', max_length=MAX_LENGTH)\n",
        "test_encodings = tokenizer(test_descs, truncation=True, padding='max_length', max_length=MAX_LENGTH)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0iinGBfFnvY",
        "outputId": "d85bbd61-329e-4c18-c908-0a565e965ffe"
      },
      "source": [
        "test['simple_class'].isna().sum()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MdZvdQd6EST"
      },
      "source": [
        "class ClassificationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # Encodings are dictionaries that include list of lists for the keys: \n",
        "        # 'input_ids', 'attention_mask', 'token_type_ids'\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ed5EWFuO1UC"
      },
      "source": [
        "train_dataset = ClassificationDataset(train_encodings, train_labels)\n",
        "val_dataset = ClassificationDataset(val_encodings, valid_labels)\n",
        "test_dataset = ClassificationDataset(test_encodings, test_labels)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfEGCns2u5Ss"
      },
      "source": [
        "#BertForSequenceClassification.forward?"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuqQHvfWIWay"
      },
      "source": [
        "## Fine-tuning the model\n",
        "Now that we have our datasets ready, we can move to training. For this we'll use Transformers' Trainer class. Trainer is training and evaluation loop for PyTorch, optimized for Transformers. (There is also TFTrainer for Tensorflow, but we won't go into that.) We could have also used native PyTorch training, but the Trainer class streamlines the training process and provides useful abstractions for quickly customize the training. Hence, we'll go through it. For an example of native PyTorch fine-tuning, you can go through this notebook here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkSgg1jVIwue"
      },
      "source": [
        "\n",
        "## Training Arguments¶\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtnfUBG5INfk"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",            \n",
        "    evaluation_strategy=\"epoch\",   \n",
        "    logging_steps=100,\n",
        "    num_train_epochs=10,                \n",
        "    per_device_train_batch_size=64,    \n",
        "    per_device_eval_batch_size=64,     \n",
        "    learning_rate=5.9e-05,                \n",
        "    max_grad_norm=1.0,                 \n",
        "    lr_scheduler_type='cosine_with_restarts',           \n",
        "    warmup_steps=100,               \n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        "    seed=16\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnS_HnQfIcHO"
      },
      "source": [
        "accuracy = load_metric('accuracy')\n",
        "f1 = load_metric('f1')\n",
        "precision = load_metric('precision')\n",
        "recall = load_metric('recall')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTGcA8DcI-1J"
      },
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    # Evaluation will return a tuple of (predictions and labels). Predictions will be the logit values.\n",
        "    predictions, labels = eval_pred\n",
        "    \n",
        "    # We argmax the prediction array to get the predicted classes\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    # The datasets metrics has the compute method, which returns a dictionary with the name of the metric as the key.\n",
        "    acc_score = accuracy.compute(predictions=predictions, references=labels)['accuracy']\n",
        "    f1_score = f1.compute(predictions=predictions, references=labels)['f1']\n",
        "    precision_score = precision.compute(predictions=predictions, references=labels)['precision']\n",
        "    recall_score = recall.compute(predictions=predictions, references=labels)['recall']\n",
        "    \n",
        "    return {'accuracy': acc_score, \n",
        "            \"f1\": f1_score, \n",
        "            \"recall\": recall_score, \n",
        "            \"precision\": precision_score}"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqxxMoi6JZQ8",
        "outputId": "4e18c1f0-a155-4b0e-bf63-49caa0f0cc3c"
      },
      "source": [
        "n_0 = (df_sample.simple_class==0).sum()\n",
        "n_1 = (df_sample.simple_class==1).sum()\n",
        "\n",
        "weights = [1.0, np.sqrt(n_0/n_1)]\n",
        "print(weights)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 0.7714601361995932]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tevU9Kq2JC4R"
      },
      "source": [
        "# We define our custom loss function\n",
        "w = torch.FloatTensor(weights).cuda()\n",
        "loss_fct = nn.CrossEntropyLoss(weight=w)\n",
        "\n",
        "class MyTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)        \n",
        "        logits = outputs['logits']\n",
        "        \n",
        "        # This is the only part that we change\n",
        "        loss = loss_fct(logits,labels)\n",
        "        \n",
        "        if return_outputs:\n",
        "            outputs.loss = loss\n",
        "        \n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8krjBtPJ33f"
      },
      "source": [
        "trainer = MyTrainer(\n",
        "    model=model,         \n",
        "    args=training_args,                  \n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjf7K0tzSRlw",
        "outputId": "b59b6be8-5f7f-4466-a2c7-8c15343b78dd"
      },
      "source": [
        "train_dataset.labels.dtype"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiZ-N0ODPXKd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "4ee913c8-efb7-496a-bfb3-30fafad60473"
      },
      "source": [
        "trainer.train()\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [220/220 03:12, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.684400</td>\n",
              "      <td>0.670464</td>\n",
              "      <td>0.633500</td>\n",
              "      <td>0.774253</td>\n",
              "      <td>0.988985</td>\n",
              "      <td>0.636134</td>\n",
              "      <td>7.058300</td>\n",
              "      <td>283.353000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.683000</td>\n",
              "      <td>0.669902</td>\n",
              "      <td>0.596500</td>\n",
              "      <td>0.718128</td>\n",
              "      <td>0.808812</td>\n",
              "      <td>0.645729</td>\n",
              "      <td>7.461600</td>\n",
              "      <td>268.040000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=220, training_loss=0.6833536234768954, metrics={'train_runtime': 193.593, 'train_samples_per_second': 1.136, 'total_flos': 669013191168000.0, 'epoch': 2.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 497793024, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': -129097728, 'train_mem_gpu_alloc_delta': 2082668032, 'train_mem_cpu_peaked_delta': 129544192, 'train_mem_gpu_peaked_delta': 2546023424})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5q6LEDsPXzY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a523b10b-3e6d-45a8-eeb7-ddb40f1c3258"
      },
      "source": [
        "trainer.evaluate(test_dataset)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.603,\n",
              " 'eval_f1': 0.7517198248905566,\n",
              " 'eval_loss': 0.6816092133522034,\n",
              " 'eval_mem_cpu_alloc_delta': 143360,\n",
              " 'eval_mem_cpu_peaked_delta': 0,\n",
              " 'eval_mem_gpu_alloc_delta': 0,\n",
              " 'eval_mem_gpu_peaked_delta': 214030848,\n",
              " 'eval_precision': 0.6034136546184738,\n",
              " 'eval_recall': 0.9966832504145937,\n",
              " 'eval_runtime': 3.6452,\n",
              " 'eval_samples_per_second': 274.333}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    }
  ]
}